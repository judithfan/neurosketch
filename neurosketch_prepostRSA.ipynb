{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## April 10 2017\n",
    "## Judy Fan (jefan@)\n",
    "## DESIGN ## ## ## ## \n",
    "## There are four objects (bed, bench, chair, table). Participants viewed each object 20 times per run.\n",
    "## Runs 1 & 2 -- reserved to conduct searchlight\n",
    "## Runs 3 & 4 -- pretest phase \n",
    "## Four training runs involving practice drawing two of the trained objects. \n",
    "## Runs 5 & 6 -- posttest phase\n",
    "## GOAL ## ## ## ## \n",
    "## Compare similarity between Trained object representations before and after training (vs. Control) in several\n",
    "## anatomically-defined ROIs. To do this, define `representation' as cope maps generated \n",
    "## upon fitting GLM to each object for each run. Build object x voxel matrix (4xK) for each run, vertically concatenate\n",
    "## the two runs in each phase, and compute correlation matrix. Consider M = off-diagonal 4x4 block [:4,4:8].\n",
    "## Make sure the rows are sorted such that the first two are the Trained, and the last two are the Control objects.\n",
    "## Now take the the top-left 2x2 matrix within M and let's call it M-trained. The bottom-right 2x2 = M-control.\n",
    "## The diagonal elements of M-trained (A,D depicted below) reflect the representational similarity for the *same* object between runs.\n",
    "## The off diagonal elements of M-trained (B,C) reflect the similarity between different objects across runs. \n",
    "## [_A_|_B_]\n",
    "## [_C_|_D_]\n",
    "## Mean of (B,C) - Mean(A,D) = Representational distance between objects in this phase. \n",
    "## Do the above for the pretest, then for the posttest, and compare.\n",
    "## NOTE: On the 'sketchloop' machine, data are found in sketchloop02 directory at the same level as this 'neurosketch' \n",
    "## analysis directory, and are organized by subject.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "matplotlib.use(\"Pdf\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "\n",
    "import brainiak\n",
    "import nilearn\n",
    "import nibabel\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances as pd\n",
    "from sklearn import svm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in experimental design pickle file\n",
    "import _pickle as cPickle\n",
    "\n",
    "with open('morph_drawing_training_design.pkl', 'rb') as f:\n",
    "    mdtd = cPickle.load(f, encoding='latin1') \n",
    "    \n",
    "def get_object_index(morphline,morphnum):\n",
    "    furniture_axes = ['bedChair', 'bedTable', 'benchBed', 'chairBench', 'chairTable', 'tableBench']\n",
    "    car_axes = ['limoToSUV','limoToSedan','limoToSmart','smartToSedan','suvToSedan','suvToSmart']  \n",
    "    furniture_items = ['bed','bench','chair','table']\n",
    "    car_items = ['limo','sedan','smartcar','SUV']               \n",
    "    endpoints = mdr_helpers.getEndpoints(morphline)\n",
    "    morphnum = float(morphnum)\n",
    "    whichEndpoint = int(np.round(morphnum/100))\n",
    "    thing = endpoints[whichEndpoint]\n",
    "    if morphline in furniture_axes:\n",
    "        return furniture_items.index(thing)+1\n",
    "    elif morphline in car_axes:\n",
    "        return car_items.index(thing)+1    \n",
    "    \n",
    "def getEndpoints(morphline):    \n",
    "    if morphline=='sedanMinivan':\n",
    "        return ['sedan','minivan']\n",
    "    elif morphline=='minivanSportscar':\n",
    "        return ['minivan','sportscar']\n",
    "    elif morphline=='sportscarSUV':\n",
    "        return ['sportscar','SUV']\n",
    "    elif morphline=='SUVMinivan':\n",
    "        return ['SUV','minivan']\n",
    "    elif morphline=='sportscarSedan':\n",
    "        return ['sportscar','sedan']\n",
    "    elif morphline=='sedanSUV':\n",
    "        return ['sedan','SUV']\n",
    "    elif morphline=='bedChair':\n",
    "        return ['bed','chair']\n",
    "    elif morphline=='bedTable':\n",
    "        return ['bed','table']\n",
    "    elif morphline=='benchBed':\n",
    "        return ['bench','bed']\n",
    "    elif morphline=='chairBench':\n",
    "        return ['chair','bench']\n",
    "    elif morphline=='chairTable':\n",
    "        return ['chair','table']\n",
    "    elif morphline=='tableBench':\n",
    "        return ['table','bench']\n",
    "    elif morphline=='limoToSUV':\n",
    "        return ['limo','SUV']    \n",
    "    elif morphline=='limoToSedan':\n",
    "        return ['sedan','limo']  \n",
    "    elif morphline=='limoToSmart':\n",
    "        return ['limo','smartcar']  \n",
    "    elif morphline=='smartToSedan':\n",
    "        return ['smartcar','sedan']    \n",
    "    elif morphline=='suvToSedan':\n",
    "        return ['SUV','sedan']  \n",
    "    elif morphline=='suvToSmart':\n",
    "        return ['SUV','smartcar']  \n",
    "    else:\n",
    "        return ['A','B']          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# behavioral data from database\n",
    "import pymongo as pm\n",
    "from pymongo import MongoClient\n",
    "conn = MongoClient('localhost', 20809)\n",
    "\n",
    "DBNAME = conn['during_morph_drawing_recognition']\n",
    "COLNAME = DBNAME['fmri3.files']\n",
    "coll=COLNAME\n",
    "DATADIR = 'neurosketch_data_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #### test out extraction of trained and control object labels\n",
    "\n",
    "# w = sub_dirs[0]\n",
    "# these = coll.find({'wID': w}).sort('trialNum')   \n",
    "# versionNum = these[0]['versionNum']\n",
    "\n",
    "# design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "# trained = design[0]['trained']\n",
    "# near = design[0]['near']\n",
    "# far1 = design[0]['far1']\n",
    "# far2 = design[0]['far2']\n",
    "\n",
    "# endpoints = getEndpoints(trained)\n",
    "# print('trained: ' + str(endpoints))\n",
    "\n",
    "# endpoints = getEndpoints(near)\n",
    "# print('control: ' + str(endpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get list of subject directories\n",
    "proj_dir = '/home/jefan/sketchloop02'\n",
    "contents_dir = os.listdir(proj_dir)\n",
    "\n",
    "sub_dirs = []\n",
    "for i in contents_dir:\n",
    "    try:\n",
    "        if i.split('_')[1]=='neurosketch':\n",
    "            sub_dirs.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sub_dirs = sorted(sub_dirs)\n",
    "\n",
    "# issue with 1207161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1207161_neurosketch']\n",
    "\n",
    "print(sub_dirs)\n",
    "print(str(len(sub_dirs)) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do for single subject for now\n",
    "this_sub = sub_dirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis1_path = os.path.join(proj_dir,s,'analysis','firstlevel')\n",
    "analysis1_dirs = os.listdir(analysis1_path)\n",
    "if 'glm4_recognition_run_1+.feat' in analysis1_dirs:\n",
    "    print('Check to make sure you get rid of redundant/incomplete GLM folders for this subject')\n",
    "print(sorted(analysis1_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## glm output directories by run number\n",
    "pre1 = 'glm4_recognition_run_3.feat'\n",
    "pre2 = 'glm4_recognition_run_4.feat'\n",
    "post1 = 'glm4_recognition_run_5.feat'\n",
    "post2 = 'glm4_recognition_run_6.feat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_path = os.path.join(proj_dir,s,'analysis','firstlevel',pre1,'stats')\n",
    "contents_stats_dir = os.listdir(stats_path)\n",
    "print(sorted(contents_stats_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "nifti_path = os.path.join(proj_dir,s,'analysis','firstlevel',post1,'stats','cope1.nii.gz')\n",
    "plotting.plot_glass_brain(nifti_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmri_img = image.smooth_img(nifti_path,fwhm=3)\n",
    "from nilearn.plotting import plot_epi\n",
    "mean_img = image.mean_img(fmri_img)\n",
    "plot_epi(mean_img, title='Smoothed mean EPI', cut_coords=[-37,-25,-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load ROI mask\n",
    "rois_path = os.path.join(proj_dir,s,'analysis','firstlevel','rois')\n",
    "contents_rois = os.listdir(rois_path)\n",
    "# print(sorted(contents_rois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cope numbering legend\n",
    "## cope1 = 'bed'\n",
    "## cope2 = 'bench'\n",
    "## cope3 = 'chair'\n",
    "## cope4 = 'table'\n",
    "\n",
    "cope2obj = {'cope1':'bed','cope2':'bench', 'cope3':'chair','cope4':'table'}\n",
    "obj2cope = {'bed':1,'bench':2, 'chair':3,'table':4}\n",
    "\n",
    "def triple_sum(X):\n",
    "    return sum(sum(sum(X)))\n",
    "\n",
    "def get_mask_array(mask_path):\n",
    "    mask_img = image.load_img(mask_path)\n",
    "    mask_data = mask_img.get_data()\n",
    "    num_brain_voxels = sum(sum(sum(mask_data==1)))\n",
    "    return mask_data, num_brain_voxels\n",
    "    \n",
    "def load_roi_mask(subj,run_num,roi):\n",
    "    mask_path = proj_dir + subj +'/analysis/firstlevel/rois/' + roi + '_func__' + str(run_num) + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data\n",
    "\n",
    "def load_roi_mask_combined(subj,run_num,roi):\n",
    "    if run_num in [1,2]:\n",
    "        phase_num = '12'\n",
    "    elif run_num in [3,4]:\n",
    "        phase_num = '34'\n",
    "    elif run_num in [5,6]:\n",
    "        phase_num = '56'\n",
    "    mask_path = proj_dir + '/' + subj +'/analysis/firstlevel/rois/' + roi + '_func_combined_' + phase_num + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data\n",
    "\n",
    "def normalize(X):\n",
    "    mn = X.mean(0)\n",
    "    sd = X.std(0)\n",
    "    X = X - mn\n",
    "    X = X / np.maximum(sd, 1e-5)\n",
    "    return X\n",
    "\n",
    "def load_single_run_weights(subj,run_num,cope_num):\n",
    "    nifti_path = proj_dir + '/' + subj + '/analysis/firstlevel/glm4_recognition_run_' + str(run_num) + \\\n",
    "                '.feat/stats/' + 'cope' + str(cope_num) + '.nii.gz'\n",
    "    fmri_img = image.load_img(nifti_path)\n",
    "    fmri_data = fmri_img.get_data()\n",
    "    return fmri_data\n",
    "\n",
    "def apply_mask(data,mask):\n",
    "    return data[mask==1]\n",
    "\n",
    "def load_data_and_apply_mask(subj,run_num,roi,cope_num):\n",
    "    mask = load_roi_mask_combined(subj,run_num,roi)\n",
    "    vol = load_single_run_weights(subj,run_num,cope_num)\n",
    "    vec = apply_mask(vol,mask)\n",
    "    return vec\n",
    "\n",
    "def extract_obj_by_voxel_run_mat(this_sub,run_num, roi):\n",
    "    cope1 = load_data_and_apply_mask(this_sub,run_num,roi,1)\n",
    "    cope2 = load_data_and_apply_mask(this_sub,run_num,roi,2)\n",
    "    cope3 = load_data_and_apply_mask(this_sub,run_num,roi,3)\n",
    "    cope4 = load_data_and_apply_mask(this_sub,run_num,roi,4)\n",
    "    return np.vstack((cope1,cope2,cope3,cope4))\n",
    "\n",
    "def plot_phase_RSM(this_sub,roi,phase):\n",
    "    '''\n",
    "    e.g., plot_phase_RSM(this_sub,'fusiform','pre')\n",
    "    '''\n",
    "    if phase=='pre':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,6,roi)        \n",
    "    stacked = np.vstack((mat1,mat2))\n",
    "    plt.matshow(np.corrcoef(stacked))\n",
    "    plt.colorbar()\n",
    "\n",
    "    \n",
    "def extract_condition_by_voxel_run_mat(this_sub,run_num, roi):\n",
    "    w = this_sub\n",
    "    these = coll.find({'wID': w}).sort('trialNum')   \n",
    "    versionNum = these[0]['versionNum']\n",
    "\n",
    "    design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "    trained = design[0]['trained']\n",
    "    near = design[0]['near']\n",
    "    far1 = design[0]['far1']\n",
    "    far2 = design[0]['far2']\n",
    "\n",
    "    Tep = getEndpoints(trained)\n",
    "    Nep = getEndpoints(near)\n",
    "    condorder = Tep + Nep\n",
    "\n",
    "    slot1 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[0]])\n",
    "    slot2 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[1]])\n",
    "    slot3 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[2]])\n",
    "    slot4 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[3]])\n",
    "    return np.vstack((slot1,slot2,slot3,slot4))\n",
    "    \n",
    "    \n",
    "def remove_nans(array):\n",
    "    return array[~np.isnan(array)]\n",
    "\n",
    "def rmse(a):\n",
    "    return np.sqrt(np.mean(map(np.square,a)))\n",
    "\n",
    "def betwitdist(a,b,ab):\n",
    "    return ab/np.sqrt(0.5*(a**2+b**2))\n",
    "\n",
    "def norm_hist(data,bins):\n",
    "    weights = np.ones_like(data)/float(len(data))\n",
    "    plt.hist(data, bins=bins, weights=weights)\n",
    "    \n",
    "def compare_btw_wit_obj_similarity_across_runs(this_sub,phase,roi):\n",
    "    if phase=='pre':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,6,roi)        \n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    DAB = sklearn.metrics.pairwise.pairwise_distances(fAB, metric='correlation') # square matrix, where off-diagblock is distances *between* fA and fB vectors\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "    wit_obj = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])].diagonal()\n",
    "    btw_obj = np.hstack((offblock[np.triu_indices(shape(offblock)[0],k=1)],offblock[np.tril_indices(shape(offblock)[0],k=-1)]))\n",
    "    wit_mean = wit_obj.mean()\n",
    "    btw_mean = btw_obj.mean()\n",
    "    return wit_mean,btw_mean\n",
    "\n",
    "def compare_btw_wit_cond_similarity_across_runs(this_sub,phase,roi):\n",
    "\n",
    "    if phase=='pre':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,6,roi)\n",
    "\n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    DAB = sklearn.metrics.pairwise.pairwise_distances(fAB, metric='correlation') # square matrix, where off-diagblock is distances *between* fA and fB vectors\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "\n",
    "    trained_witobj = offblock.diagonal()[:2]\n",
    "    control_witobj = offblock.diagonal()[2:]\n",
    "    trained_btwobj = np.array([offblock[:2,:2][0,1], offblock[:2,:2][1,0]])\n",
    "    control_btwobj = np.array([offblock[2:,2:][0,1],offblock[2:,2:][1,0]])\n",
    "\n",
    "    trawit_mean = trained_witobj.mean()\n",
    "    conwit_mean = control_witobj.mean()\n",
    "    trabtw_mean = trained_btwobj.mean()\n",
    "    conbtw_mean = control_btwobj.mean()\n",
    "    return trawit_mean,conwit_mean,trabtw_mean,conbtw_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trawit_mean_pre,conwit_mean_pre,trabtw_mean_pre,conbtw_mean_pre = compare_btw_wit_cond_similarity_across_runs(this_sub,'pre','fusiform')\n",
    "trawit_mean_post,conwit_mean_post,trabtw_mean_post,conbtw_mean_post = compare_btw_wit_cond_similarity_across_runs(this_sub,'post','fusiform')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tradiff_pre = trabtw_mean_pre - trawit_mean_pre\n",
    "condiff_pre = conbtw_mean_pre - conwit_mean_pre\n",
    "\n",
    "tradiff_post = trabtw_mean_post - trawit_mean_post\n",
    "condiff_post = conbtw_mean_post - conwit_mean_post\n",
    "\n",
    "print('Trained Btw-Wit Post-Pre: ' + str(tradiff_post-tradiff_pre))\n",
    "print('Control Btw-Wit Post-Pre: ' + str(condiff_post-condiff_pre))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### April 8 2017\n",
    "### get differentiation by CONDITION (not JUST by object category (see below))\n",
    "\n",
    "Tradiffpre = []\n",
    "Condiffpre = []\n",
    "Tradiffpost = []\n",
    "Condiffpost = []\n",
    "\n",
    "ROIs = ['V1','fusiform','IT','LOC','occitemp']\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)    \n",
    "    _Tradiffpre = []\n",
    "    _Condiffpre = []\n",
    "    _Tradiffpost = []\n",
    "    _Condiffpost = []\n",
    "        \n",
    "    for s in sub_dirs:\n",
    "#         print(s)\n",
    "        trawit_mean_pre,conwit_mean_pre, trabtw_mean_pre,conbtw_mean_pre = \\\n",
    "        compare_btw_wit_cond_similarity_across_runs(s,'pre',roi)\n",
    "        trawit_mean_post,conwit_mean_post, trabtw_mean_post,conbtw_mean_post = \\\n",
    "        compare_btw_wit_cond_similarity_across_runs(s,'post',roi)\n",
    "        \n",
    "        _Tradiffpre.append(trabtw_mean_pre - trawit_mean_pre)\n",
    "        _Condiffpre.append(conbtw_mean_pre - conwit_mean_pre)\n",
    "\n",
    "        _Tradiffpost.append(trabtw_mean_post - trawit_mean_post)\n",
    "        _Condiffpost.append(conbtw_mean_post - conwit_mean_post)\n",
    "        \n",
    "    _Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost = map(np.array, \\\n",
    "                                                               [_Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost])\n",
    "        \n",
    "    if len(Tradiffpre)==0:\n",
    "        Tradiffpre = _Tradiffpre\n",
    "        Condiffpre = _Condiffpre\n",
    "        Tradiffpost = _Tradiffpost\n",
    "        Condiffpost = _Condiffpost\n",
    "    else:\n",
    "        Tradiffpre = np.vstack((Tradiffpre,_Tradiffpre))\n",
    "        Condiffpre = np.vstack((Condiffpre,_Condiffpre))\n",
    "        Tradiffpost = np.vstack((Tradiffpost,_Tradiffpost))\n",
    "        Condiffpost = np.vstack((Condiffpost,_Condiffpost))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"prepost_differentiation_by_condition.pkl\", 'wb')  as _f:\n",
    "    cPickle.dump([Tradiffpost,Tradiffpre,Condiffpost,Condiffpre], _f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Trained Btw-Wit Post-Pre: ' + str(Tradiffpost-Tradiffpre))\n",
    "# print('Control Btw-Wit Post-Pre: ' + str(Condiffpost-Condiffpre))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('prepost_differentiation_by_condition.pkl', 'rb') as f:\n",
    "    prepost_diff = cPickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tradifflearn = Tradiffpost-Tradiffpre\n",
    "Condifflearn = Condiffpost-Condiffpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ROIs = ['V1','fusiform','IT','LOC','occitemp']\n",
    "print(Tradifflearn.mean(1))\n",
    "print(Condifflearn.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = plt.hist(Condiffpre[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Tradifflearn[2],Condifflearn[2])\n",
    "plt.plot([-0.15,0.15],[-0.15,0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tradiffpre.mean(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### get differentiation by object category (ignoring training condition)\n",
    "Witpre = []\n",
    "Btwpre = []\n",
    "Witpost = []\n",
    "Btwpost = []\n",
    "Diffpre = []\n",
    "Diffpost = []\n",
    "\n",
    "ROIs = ['V1','fusiform','paraphippo','IT','LOC','occitemp']\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)\n",
    "    _Witpre = []\n",
    "    _Btwpre = []\n",
    "    _Witpost = []\n",
    "    _Btwpost = []\n",
    "    _Diffpre = []\n",
    "    _Diffpost = []\n",
    "    for s in sub_dirs:\n",
    "        wit_pre,btw_pre = compare_btw_wit_obj_similarity_across_runs(s,'pre',roi)\n",
    "        wit_post,btw_post = compare_btw_wit_obj_similarity_across_runs(s,'post',roi)\n",
    "        _Diffpre.append(btw_pre-wit_pre)\n",
    "        _Diffpost.append(btw_post-wit_post)    \n",
    "        _Witpre.append(wit_pre)\n",
    "        _Btwpre.append(btw_pre)\n",
    "        _Witpost.append(wit_post)\n",
    "        _Btwpost.append(btw_post)    \n",
    "\n",
    "    _Witpre,_Btwpre,_Witpost,_Btwpost,_Diffpre,_Diffpost = map(np.array,[_Witpre,_Btwpre,_Witpost,_Btwpost,_Diffpre,_Diffpost])\n",
    "    \n",
    "    if len(Witpre)==0:\n",
    "        Witpre = _Witpre\n",
    "        Btwpre = _Btwpre\n",
    "        Witpost = _Witpost\n",
    "        Btwpost = _Btwpost\n",
    "        Diffpre = _Diffpre\n",
    "        Diffpost = _Diffpost\n",
    "    else:\n",
    "        Witpre = np.vstack((Witpre,_Witpre))\n",
    "        Btwpre = np.vstack((Btwpre,_Btwpre))   \n",
    "        Witpost = np.vstack((Witpost,_Witpost))\n",
    "        Btwpost = np.vstack((Btwpost,_Btwpost)) \n",
    "        Diffpre = np.vstack((Diffpre,_Diffpre))\n",
    "        Diffpost = np.vstack((Diffpost,_Diffpost))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
